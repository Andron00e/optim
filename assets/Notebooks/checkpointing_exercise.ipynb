{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate -U"
      ],
      "metadata": {
        "id": "GQJLeC1p155K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets pynvml"
      ],
      "metadata": {
        "id": "8Ri81rj216OF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from datasets import Dataset\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, logging\n",
        "from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo\n",
        "import torch\n",
        "\n",
        "# Initialize GPU monitoring\n",
        "nvmlInit()\n",
        "\n",
        "def print_gpu_utilization():\n",
        "    handle = nvmlDeviceGetHandleByIndex(0)\n",
        "    info = nvmlDeviceGetMemoryInfo(handle)\n",
        "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
        "\n",
        "def print_summary(result):\n",
        "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
        "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
        "    print_gpu_utilization()\n",
        "\n",
        "# Create dummy data\n",
        "seq_len, dataset_size = 512, 512\n",
        "dummy_data = {\n",
        "    \"input_ids\": np.random.randint(100, 30000, (dataset_size, seq_len)),\n",
        "    \"labels\": np.random.randint(0, 1, (dataset_size)),\n",
        "}\n",
        "ds = Dataset.from_dict(dummy_data)\n",
        "ds.set_format(\"pt\")\n",
        "\n",
        "# Load model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-large-uncased\").to(\"cuda\")\n",
        "\n",
        "# Training arguments without gradient checkpointing\n",
        "default_args = {\n",
        "    \"output_dir\": \"tmp\",\n",
        "    \"evaluation_strategy\": \"steps\",\n",
        "    \"num_train_epochs\": 1,\n",
        "    \"log_level\": \"error\",\n",
        "    \"report_to\": \"none\",\n",
        "}\n",
        "training_args = TrainingArguments(per_device_train_batch_size=4, **default_args)\n",
        "trainer = Trainer(model=model, args=training_args, train_dataset=ds)\n",
        "\n",
        "# Train and summarize\n",
        "result = trainer.train()\n",
        "print_summary(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "Trfpnf8tytua",
        "outputId": "391cf232-5551-46fb-9b2c-a1acee0d3f94"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [128/128 02:54, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 177.67\n",
            "Samples/second: 2.88\n",
            "GPU memory occupied: 7982 MB.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset the environment (necessary to ensure accurate memory usage reporting)\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Training arguments with gradient checkpointing\n",
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    gradient_checkpointing=True,\n",
        "    **default_args\n",
        ")\n",
        "trainer = Trainer(model=model, args=training_args, train_dataset=ds)\n",
        "\n",
        "# Train and summarize\n",
        "result = trainer.train()\n",
        "print_summary(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQjgXdDF1UtX",
        "outputId": "50fcd061-7c67-44e7-932f-95a317e20145"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train_runtime': 266.2248, 'train_samples_per_second': 1.923, 'train_steps_per_second': 0.481, 'train_loss': 0.04136791452765465, 'epoch': 1.0}\n",
            "Time: 266.22\n",
            "Samples/second: 1.92\n",
            "GPU memory occupied: 6834 MB.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise:\n",
        "\n",
        "Estimate maximum batch size, that fits Colab GPU memory without and with checkpointing until it raise OOM (Out of memory) error.\n",
        "\n",
        "| Without checkpointing | With checkpointing |\n",
        "|:---:|:---:|\n",
        "| ? | ? |\n",
        "\n"
      ],
      "metadata": {
        "id": "ybYK5yH-2Fbe"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "convnet-vgg16.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "371px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}